import cv2
import numpy as np

def detect_non_matching_areas_connected_components(image1_path, image2_path, output_image_path, cell_size=50, match_threshold=0.7):
    """
    Detects non-matching areas between two images using FAST and feature matching,
    draws bounding boxes around *separate* non-matching regions using connected components.
    Saves the result to an output image file.

    Args:
        image1_path: Path to the first image (reference image - e.g., template image).
        image2_path: Path to the second image (e.g., actual image).
        output_image_path: Path to save the output image with bounding boxes.
        cell_size: Size of the grid cells to divide the image into.
        match_threshold: Minimum ratio test threshold for good matches (adjust as needed).

    Returns:
        True if successful, False otherwise (e.g., image loading error).
    """

    print(f"Loading images: {image1_path}, {image2_path}")
    img1 = cv2.imread(image1_path, cv2.IMREAD_GRAYSCALE)
    img2 = cv2.imread(image2_path, cv2.IMREAD_GRAYSCALE)

    if img1 is None or img2 is None:
        print("Error: Could not load images. Please check image paths.")
        return False

    print(f"Image 1 shape: {img1.shape}, Image 2 shape: {img2.shape}")

    # 1. Feature Detection (FAST)
    fast = cv2.FastFeatureDetector_create()
    kp1 = fast.detect(img1, None)
    kp2 = fast.detect(img2, None)
    print(f"Detected FAST keypoints - Image 1: {len(kp1)}, Image 2: {len(kp2)}")

    # 2. Feature Description (ORB)
    orb = cv2.ORB_create()
    kp1, des1 = orb.compute(img1, kp1)
    kp2, des2 = orb.compute(img2, kp2)

    if des1 is None or des2 is None:
        print("Warning: No descriptors computed. Check if enough keypoints were detected.")
        cv2.imwrite(output_image_path, cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR))
        return True

    print(f"Computed ORB descriptors - Image 1: {des1.shape if des1 is not None else None}, Image 2: {des2.shape if des2 is not None else None}")

    # 3. Feature Matching (Brute-Force)
    bf = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=False)
    matches = bf.knnMatch(des1, des2, k=2)
    print(f"Initial matches found: {len(matches)}")

    # 4. Ratio test
    good_matches = []
    for m, n in matches:
        if m.distance < match_threshold * n.distance:
            good_matches.append(m)
    print(f"Good matches after ratio test: {len(good_matches)}")

    # 5. Grid-based Non-Matching Area Identification
    h, w = img1.shape
    grid_h = h // cell_size
    grid_w = w // cell_size
    non_matching_cells = np.zeros((grid_h, grid_w), dtype=np.uint8)
    non_matching_cells[:] = 1 # Initialize all as non-matching

    if good_matches:
        for match in good_matches:
            idx1 = match.queryIdx
            pt1 = kp1[idx1].pt
            cell_row = int(pt1[1] // cell_size)
            cell_col = int(pt1[0] // cell_size)
            if 0 <= cell_row < grid_h and 0 <= cell_col < grid_w:
                non_matching_cells[cell_row, cell_col] = 0 # Mark cell as matching

    print("Non-matching cells grid:\n", non_matching_cells)

    # 6. Connected Components Analysis and Bounding Boxes
    image_with_boxes = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)

    # Convert non_matching_cells (0 and 1) to binary image (0 and 255) for connected components
    binary_non_matching_cells = (non_matching_cells * 255).astype(np.uint8)

    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_non_matching_cells, connectivity=8)

    print(f"Connected components found: {num_labels - 1} (excluding background)") # num_labels includes background

    # Iterate through connected components (start from 1 to skip background component 0)
    for label in range(1, num_labels):
        x = stats[label, cv2.CC_STAT_LEFT]
        y = stats[label, cv2.CC_STAT_TOP]
        w_region = stats[label, cv2.CC_STAT_WIDTH]
        h_region = stats[label, cv2.CC_STAT_HEIGHT]
        area = stats[label, cv2.CC_STAT_AREA]

        # Filter out very small regions if needed (e.g., area > some_threshold)
        if area > 10: # Example: Minimum area threshold - adjust as needed
            x1 = x * cell_size
            y1 = y * cell_size
            x2 = (x + w_region) * cell_size
            y2 = (y + h_region) * cell_size
            cv2.rectangle(image_with_boxes, (x1, y1), (x2, y2), (0, 0, 255), 2)
            print(f"Bounding box (component {label}): ({x1}, {y1}), ({x2}, {y2}), Area: {area}")


    cv2.imwrite(output_image_path, image_with_boxes)
    print(f"Output image saved to: {output_image_path}")
    return True

if __name__ == '__main__':
    template_image_path = 'image1.jpg' # Replace with your template image path
    actual_image_path = 'image3.jpg'   # Replace with your actual image path
    output_path = 'output_non_matching_areas_components.jpg' # Changed output path

    # Create dummy images for demonstration
    dummy_img1 = np.zeros((300, 400), dtype=np.uint8)
    dummy_img1[50:100, 50:100] = 255
    dummy_img1[200:250, 300:350] = 255 # Two separate squares in image 1
    dummy_img2 = np.zeros((300, 400), dtype=np.uint8)
    dummy_img2[75:125, 75:125] = 255 # Shifted square in image 2

    cv2.imwrite('template_image.jpg', dummy_img1)
    cv2.imwrite('actual_image.jpg', dummy_img2)


    if detect_non_matching_areas_connected_components(template_image_path, actual_image_path, output_path):
        print(f"Non-matching areas detection with connected components complete. Output saved to: {output_path}")
    else:
        print("Non-matching areas detection failed. See errors above.")